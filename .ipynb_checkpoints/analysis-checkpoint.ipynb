{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1346a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import abspath\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "888ffd59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/08/09 15:18:50 INFO org.apache.spark.SparkEnv: Registering MapOutputTracker\n",
      "22/08/09 15:18:50 INFO org.apache.spark.SparkEnv: Registering BlockManagerMaster\n",
      "22/08/09 15:18:50 INFO org.apache.spark.SparkEnv: Registering BlockManagerMasterHeartbeat\n",
      "22/08/09 15:18:50 INFO org.apache.spark.SparkEnv: Registering OutputCommitCoordinator\n"
     ]
    }
   ],
   "source": [
    "warehouse_location = abspath('spark-warehouse')\n",
    "scSpark = SparkSession.builder \\\n",
    "    .appName(\"Spark Hive\") \\\n",
    "    .config(\"spark.sql.warehouse.dir\", warehouse_location) \\\n",
    "    .enableHiveSupport() \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33119f8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ivysettings.xml file not found in HIVE_HOME or HIVE_CONF_DIR,/etc/hive/conf.dist/ivysettings.xml will be used\n",
      "22/08/09 15:19:18 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \n",
      "java.lang.InterruptedException\n",
      "\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n",
      "\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n",
      "\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n",
      "\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "22/08/09 15:19:33 WARN org.apache.spark.scheduler.cluster.YarnScheduler: Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient resources\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+----------------+----------+--------------+--------------+----------+--------+--------------------+\n",
      "|       kota| cuaca| cuaca_deskripsi|temperatur|temperatur_min|temperatur_max|      date|   waktu|             created|\n",
      "+-----------+------+----------------+----------+--------------+--------------+----------+--------+--------------------+\n",
      "|    Bandung|Clouds|   broken clouds|    294.28|        294.28|        294.28|2022-08-09|14:58:13| 2022-08-09T14:58:13|\n",
      "|      Medan|  Haze|            haze|    299.83|        299.83|        300.17|2022-08-09|14:58:12| 2022-08-09T14:58:12|\n",
      "|     Lombok|Clouds| overcast clouds|    294.42|        294.42|        294.42|2022-08-09|13:49:15| 2022-08-09T13:49:15|\n",
      "|     Lombok|Clouds|   broken clouds|    294.07|        294.07|        294.07|2022-08-09|14:58:12| 2022-08-09T14:58:12|\n",
      "|Labuan Bajo|Clouds|      few clouds|    297.42|        297.42|        297.42|2022-08-09|14:58:12| 2022-08-09T14:58:12|\n",
      "|       Bali|Clouds| overcast clouds|    298.28|        298.28|        298.69|2022-08-09|13:26:50| 2022-08-09T13:26:50|\n",
      "|       Bali|Clouds| overcast clouds|    298.28|        298.28|        298.69|2022-08-09|13:49:14| 2022-08-09T13:49:14|\n",
      "|       Bali|Clouds|   broken clouds|    298.28|        298.28|        298.69|2022-08-09|14:58:12| 2022-08-09T14:58:12|\n",
      "|Labuan Bajo|Clouds|scattered clouds|    297.72|        297.72|        297.72|2022-08-09|13:49:15| 2022-08-09T13:49:15|\n",
      "|     Lombok|Clouds| overcast clouds|    294.54|        294.54|        294.54|2022-08-09|13:26:50| 2022-08-09T13:26:50|\n",
      "|       Bali|Clouds| overcast clouds|    299.39|        299.39|        299.69|2022-08-09|06:31:41|2022-08-09T06:31:...|\n",
      "|    Bandung|Clouds|scattered clouds|    294.29|        294.29|        294.29|2022-08-09|13:49:15| 2022-08-09T13:49:15|\n",
      "|       Bali|Clouds| overcast clouds|    299.39|        299.39|        299.69|2022-08-09|06:31:41|2022-08-09T06:31:...|\n",
      "|      Medan|  Haze|            haze|    299.83|        299.83|        300.17|2022-08-09|13:49:15| 2022-08-09T13:49:15|\n",
      "|    Bandung|Clouds|scattered clouds|    294.45|        294.45|        294.45|2022-08-09|13:26:50| 2022-08-09T13:26:50|\n",
      "|      Medan|  Haze|            haze|    300.94|        300.94|        301.17|2022-08-09|13:26:50| 2022-08-09T13:26:50|\n",
      "|Labuan Bajo|Clouds|      few clouds|    298.14|        298.14|        298.14|2022-08-09|13:26:50| 2022-08-09T13:26:50|\n",
      "+-----------+------+----------------+----------+--------------+--------------+----------+--------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scSpark.sql(\"SELECT * FROM laporan_cuaca\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ec8a2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 3:==================================================>      (15 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------+------+\n",
      "|       kota| cuaca|jumlah|\n",
      "+-----------+------+------+\n",
      "|      Medan|  Haze|     3|\n",
      "|Labuan Bajo|Clouds|     3|\n",
      "|    Bandung|Clouds|     3|\n",
      "|       Bali|Clouds|     5|\n",
      "|     Lombok|Clouds|     3|\n",
      "+-----------+------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "scSpark.sql(\"select kota,cuaca,count(*) as jumlah from laporan_cuaca group by kota, cuaca\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd8acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/08/09 15:21:18 WARN org.apache.hadoop.util.concurrent.ExecutorHelper: Thread (Thread[GetFileInfo #1,5,main]) interrupted: \n",
      "java.lang.InterruptedException\n",
      "\tat com.google.common.util.concurrent.AbstractFuture.get(AbstractFuture.java:510)\n",
      "\tat com.google.common.util.concurrent.FluentFuture$TrustedFuture.get(FluentFuture.java:88)\n",
      "\tat org.apache.hadoop.util.concurrent.ExecutorHelper.logThrowableFromAfterExecute(ExecutorHelper.java:48)\n",
      "\tat org.apache.hadoop.util.concurrent.HadoopThreadPoolExecutor.afterExecute(HadoopThreadPoolExecutor.java:90)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1157)\n",
      "\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n",
      "\tat java.lang.Thread.run(Thread.java:750)\n",
      "[Stage 8:==================================================>      (15 + 1) / 17]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------------+\n",
      "|       kota|average_temperatur|\n",
      "+-----------+------------------+\n",
      "|      Medan|             300.2|\n",
      "|       Bali|           298.724|\n",
      "|    Bandung|            294.34|\n",
      "|     Lombok| 294.3433333333333|\n",
      "|Labuan Bajo|297.76000000000005|\n",
      "+-----------+------------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "scSpark.sql(\"select kota,avg(temperatur) as average_temperatur from laporan_cuaca group by kota\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5dda3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
